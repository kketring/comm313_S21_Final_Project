{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for pulling data from twitter and saving in structured form\n",
    "\n",
    "<h4 style='color:red'> save this file to your local computer and run there. DO NOT run large queries on the class jhub please. </h4>\n",
    "\n",
    "`JMP - 04-07-21`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "import json\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download_query_tweets was written by MBOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_query_tweets(query, date_since, date_until, max=1000):\n",
    "    print(f\"Downloading tweets for query: '{query}' from {date_since} to {date_until} (max of {max})\")\n",
    "\n",
    "    tweet_list = []\n",
    "    qu = query\n",
    "    query = f'{query} since:{date_since} until:{date_until}'\n",
    "    \n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "        if i>=max:\n",
    "            break\n",
    "    \n",
    "\n",
    "        tweet_dict = {\n",
    "            'id': tweet.id,\n",
    "            'created_at': tweet.date.strftime('%Y-%m-%d %H:%M'),\n",
    "            'text': tweet.content,\n",
    "            'username': tweet.username,\n",
    "            'query':qu\n",
    "        }\n",
    "\n",
    "        tweet_list.append(tweet_dict)\n",
    "        \n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranged_query(date_range,query,out_path,max=1000):\n",
    "    \"\"\"\n",
    "    takes start and end dates and collects tweets \n",
    "    for each query. Saves results as json grouped by year\n",
    "    \n",
    "    Args:\n",
    "        - date_range: tuple containing start and end '%Y-%m-%d'\n",
    "        - query: list containing searchable terms\n",
    "        - out_path: dir to save json files\n",
    "        - max: maximum number of tweets to search\n",
    "    \n",
    "    Returns:\n",
    "        None: saves to disc\n",
    "    \"\"\"\n",
    "    \n",
    "    since, until = date_range # a tuple of start and end date (%Y-%m-%d)\n",
    "    all_tweets = []\n",
    "    for qu in query: # for each query download tweets within range and add to larger list\n",
    "        tweet_list = download_query_tweets(qu,since,until,max=max)\n",
    "        all_tweets.extend(tweet_list)\n",
    "    \n",
    "    year = since.split('-')[0]  # get what year the query is for\n",
    "    \n",
    "    # create a folder for the year if it doesn't exist already\n",
    "    if not os.path.exists(f\"{out_path}/{year}\"):\n",
    "        os.makedirs(f\"{out_path}/{year}\")\n",
    "    \n",
    "    # save json\n",
    "    out_file_name = f\"{out_path}/{year}/{since}_{until}_{'_'.join(query)}.json\"\n",
    "    with open(out_file_name,'w') as out_file:\n",
    "        out_file.write(json.dumps(all_tweets))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "#### MAKE SURE YOU ARE IN THE DIRECTORY YOU WANT TO SAVE YOUR FILES IN\n",
    "The third argument of the ranged_query function will be the name of the folder you want to save data to (usually its called `data`). \n",
    "\n",
    "1. Create a list of date-range tuples for which to run the queries on (for example, several days within each month of the year). \n",
    "\n",
    "2. make a list of queries\n",
    "\n",
    "3. run the ranged_query function to get tweets (setting max to preferred number of results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tweets for query: '#ncaa' from 2020-04-01 to 2020-04-11 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2020-04-01 to 2020-04-11 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2020-04-01 to 2020-04-11 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2020-09-12 to 2020-09-23 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2020-09-12 to 2020-09-23 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2020-09-12 to 2020-09-23 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2019-04-01 to 2019-04-11 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2019-04-01 to 2019-04-11 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2019-04-01 to 2019-04-11 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2019-09-12 to 2019-09-23 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2019-09-12 to 2019-09-23 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2019-09-12 to 2019-09-23 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2018-04-01 to 2018-04-11 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2018-04-01 to 2018-04-11 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2018-04-01 to 2018-04-11 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2018-09-12 to 2018-09-23 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2018-09-12 to 2018-09-23 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2018-09-12 to 2018-09-23 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2017-04-01 to 2017-04-11 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2017-04-01 to 2017-04-11 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2017-04-01 to 2017-04-11 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2017-09-12 to 2017-09-23 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2017-09-12 to 2017-09-23 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2017-09-12 to 2017-09-23 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2016-04-01 to 2016-04-11 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2016-04-01 to 2016-04-11 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2016-04-01 to 2016-04-11 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2016-09-12 to 2016-09-23 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2016-09-12 to 2016-09-23 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2016-09-12 to 2016-09-23 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2015-04-01 to 2015-04-11 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2015-04-01 to 2015-04-11 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2015-04-01 to 2015-04-11 (max of 60)\n",
      "Downloading tweets for query: '#ncaa' from 2015-09-12 to 2015-09-23 (max of 60)\n",
      "Downloading tweets for query: 'ncaa' from 2015-09-12 to 2015-09-23 (max of 60)\n",
      "Downloading tweets for query: '#title9' from 2015-09-12 to 2015-09-23 (max of 60)\n"
     ]
    }
   ],
   "source": [
    "dates = [(\"2020-04-01\",'2020-04-11'),\n",
    "         ('2020-09-12','2020-09-23'),\n",
    "         ('2019-04-01','2019-04-11'),\n",
    "         ('2019-09-12','2019-09-23'),\n",
    "         ('2018-04-01','2018-04-11'),\n",
    "         ('2018-09-12','2018-09-23'),\n",
    "         ('2017-04-01','2017-04-11'),\n",
    "         ('2017-09-12','2017-09-23'),\n",
    "         ('2016-04-01','2016-04-11'),\n",
    "         ('2016-09-12','2016-09-23'),\n",
    "         ('2015-04-01','2015-04-11'),\n",
    "         ('2015-09-12','2015-09-23')\n",
    "        ]\n",
    "\n",
    "queries = ['#ncaa','ncaa','#title9']\n",
    "\n",
    "for daterange in dates:\n",
    "    ranged_query(daterange,queries,'data',60)\n",
    "    \n",
    "#'data' is where is would be written to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2019_tweets = []\n",
    "for j in os.listdir('data/2019/'):\n",
    "    with open(\"data/2019/\"+j, 'rb') as F:\n",
    "        _2019_tweets.extend(json.load(F))\n",
    "    \n",
    "    #to load back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2019_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2020_tweets = []\n",
    "for j in os.listdir('data/2020/'):\n",
    "    with open(\"data/2020/\"+j, 'rb') as F:\n",
    "        _2020_tweets.extend(json.load(F))\n",
    "    \n",
    "    #to load back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2020_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2018_tweets = []\n",
    "for j in os.listdir('data/2018/'):\n",
    "    with open(\"data/2018/\"+j, 'rb') as F:\n",
    "        _2018_tweets.extend(json.load(F))\n",
    "    \n",
    "    #to load back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2018_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2017_tweets = []\n",
    "for j in os.listdir('data/2017/'):\n",
    "    with open(\"data/2017/\"+j, 'rb') as F:\n",
    "        _2017_tweets.extend(json.load(F))\n",
    "    \n",
    "    #to load back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2017_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2016_tweets = []\n",
    "for j in os.listdir('data/2016/'):\n",
    "    with open(\"data/2016/\"+j, 'rb') as F:\n",
    "        _2016_tweets.extend(json.load(F))\n",
    "    \n",
    "    #to load back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2016_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2015_tweets = []\n",
    "for j in os.listdir('data/2015/'):\n",
    "    with open(\"data/2015/\"+j, 'rb') as F:\n",
    "        _2015_tweets.extend(json.load(F))\n",
    "    \n",
    "    #to load back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2015_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
